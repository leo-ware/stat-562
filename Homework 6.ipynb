{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ch8.4 #2,3 Ch8.5 #1,2,6 Ch8.7 #1,2,4,5,8,11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Suppose that $X_1, ..., X_n$ form a random sample from the normal distribution with unknown mean $μ$ and unknown standard deviation $σ$, and let $\\hat{\\mu}$ and $\\hat{\\sigma}$ denote the M.L.E.’s of $μ$ and $σ$. For the sample size $n = 17$, find a value of $k$ such that,**\n",
    "\n",
    "$$\n",
    "P(\\hat{\\mu} \\gt \\mu + k\\hat{\\sigma}) \\gt 0.95\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLE estimator for the variance, $\\hat{\\sigma}^2$, is given by,\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = {1 \\over n}\\sum_{i = 1}^n (X_i - \\hat{\\mu})^2\n",
    "$$\n",
    "\n",
    "Using invariance, we can get the MLE for the standard deviation by taking the square root of both sides.\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma} = \\sqrt{{1 \\over n}\\sum_{i = 1}^n (X_i - \\hat{\\mu})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma} = {1 \\over \\sqrt{n}}\\sqrt{\\sum_{i = 1}^n (X_i - \\hat{\\mu})^2}\n",
    "$$\n",
    "\n",
    "The sample standard deviation is given by,\n",
    "\n",
    "$$\n",
    "\\sigma' = \\sqrt{{1 \\over n - 1}\\sum_{i = 1}^n (X_i - \\hat{\\mu})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma' = {1 \\over \\sqrt{n - 1}}\\sqrt{\\sum_{i = 1}^n (X_i - \\hat{\\mu})^2}\n",
    "$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\n",
    "\\sigma' = {\\sqrt{n} \\over \\sqrt{n - 1}}\\hat{\\sigma}\n",
    "$$\n",
    "\n",
    "We are interested in the event $\\hat{\\mu} \\gt \\mu k\\hat{\\sigma}$.\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} \\gt \\mu k\\hat{\\sigma} = \\hat{\\mu} - \\mu \\gt k\\hat{\\sigma}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} \\gt \\mu k\\hat{\\sigma} = {\\sqrt{n} \\over \\sqrt{n - 1}}(\\hat{\\mu} - \\mu) \\gt k{\\sqrt{n} \\over \\sqrt{n - 1}}\\hat{\\sigma}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} \\gt \\mu k\\hat{\\sigma} = {\\sqrt{n} \\over \\sqrt{n - 1}}(\\hat{\\mu} - \\mu) \\gt k\\sigma'\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} \\gt \\mu k\\hat{\\sigma} = {\\sqrt{n} \\over \\sigma'}(\\hat{\\mu} - \\mu) \\gt k\\sqrt{n - 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\hat{\\mu} \\gt \\mu k\\hat{\\sigma}) = P({\\sqrt{n} \\over \\sigma'}(\\hat{\\mu} - \\mu) \\gt k\\sqrt{n - 1})\n",
    "$$\n",
    "\n",
    "We have that,\n",
    "\n",
    "$$\n",
    "{\\sqrt{n} \\over \\sigma'}(\\hat{\\mu} - \\mu) \\sim T(n - 1)\n",
    "$$\n",
    "\n",
    "Let $\\Phi$ represent the CDF of the t-distribution with $n - 1$ degrees of freedom. Let $\\Phi^{-1}$ represent the corresponding inverse CDF. Then,\n",
    "\n",
    "$$\n",
    "P({\\sqrt{n} \\over \\sigma'}(\\hat{\\mu} - \\mu) \\gt k\\sqrt{n - 1}) = 1 - \\Phi(k\\sqrt{n - 1})\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "P(\\hat{\\mu} \\gt \\mu k\\hat{\\sigma}) = 1 - \\Phi(k\\sqrt{n - 1})\n",
    "$$\n",
    "\n",
    "Suppose,\n",
    "\n",
    "$$\n",
    "P(\\hat{\\mu} \\gt \\mu k\\hat{\\sigma}) > 0.95\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "1 - \\Phi(k\\sqrt{n - 1}) \\gt 0.95\n",
    "$$\n",
    "\n",
    "$$\n",
    "1 - 0.95 \\gt \\Phi(k\\sqrt{n - 1})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\phi^{-1}(1 - 0.95) \\gt k\\sqrt{n - 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\phi^{-1}(1 - 0.95) \\over \\sqrt{n - 1}} \\gt k\n",
    "$$\n",
    "\n",
    "Suppose $n = 17$. Then,\n",
    "\n",
    "$$\n",
    "{\\phi^{-1}(0.05) \\over 4} \\gt k\n",
    "$$\n",
    "\n",
    "This value can be computed numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.4364709190690601)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "k_thresh = stats.t.ppf(0.05, 16) / 4\n",
    "k_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in this case,\n",
    "\n",
    "$$\n",
    "k \\lt -0.4364709190690601\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Suppose that the five random variables $X_1, . . . , X_5$ are i.i.d. and that each has the standard normal distribution. Determine a constant $c$ such that the random variable,**\n",
    "\n",
    "$$\n",
    "{c(X_1 + X_2) \\over (X_3^2 + X_4^2 + X_5^2)^{1/2}}\n",
    "$$\n",
    "\n",
    "**will have a t-distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let,\n",
    "\n",
    "$$\n",
    "Z ={X_1 + X_2 \\over \\sqrt{2}}\n",
    "$$\n",
    "\n",
    "Consider the distribution of $Z$. This is a sum of two normal variables, so the sum will be normal.\n",
    "\n",
    "$$\n",
    "E[{X_1 + X_2 \\over \\sqrt{2}}] = {1 \\over \\sqrt{2}}(E[X_1] + E[X_2]) = 0\n",
    "$$\n",
    "\n",
    "Since they are independent,\n",
    "\n",
    "$$\n",
    "Var[{X_1 + X_2 \\over \\sqrt{2}}] = {1 \\over 2}Var[X_1 + X_2] = {1 \\over 2}(Var[X_1] + Var[X_2]) = 1\n",
    "$$\n",
    "\n",
    "So, $Z$ is standard normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let,\n",
    "\n",
    "$$\n",
    "U(c) = {c(X_1 + X_2) \\over (X_3^2 + X_4^2 + X_5^2)^{1/2}}\n",
    "$$\n",
    "\n",
    "Consider the case when $c = {\\sqrt{3} \\over \\sqrt{2}}$.\n",
    "\n",
    "$$\n",
    "U({\\sqrt{3} / \\sqrt{2}}) =\n",
    "{{\\sqrt{3} \\over \\sqrt{2}}(X_1 + X_2) \\over (X_3^2 + X_4^2 + X_5^2)^{1/2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "U({\\sqrt{3} / \\sqrt{2}}) =\n",
    "{{1 \\over \\sqrt{2}}(X_1 + X_2) \\over {1 \\over \\sqrt{3}}(X_3^2 + X_4^2 + X_5^2)^{1/2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "U({\\sqrt{3} / \\sqrt{2}}) =\n",
    "{\\left({X_1 + X_2 \\over \\sqrt{2}}\\right) \\over \\left({X_3^2 + X_4^2 + X_5^2 \\over 3}\\right)^{1/2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "U({\\sqrt{3} / \\sqrt{2}}) =\n",
    "{Z \\over \\left({X_3^2 + X_4^2 + X_5^2 \\over 3}\\right)^{1/2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of $X_3^2$, $X_4^2$, $X_5^2$ is a squared standard normal variable. So, each is $\\chi^2(1)$ distributed. So, $U({\\sqrt{3} / \\sqrt{2}})$ is the ratio of a standard normal and the square root of the mean of three $\\chi^2(1)$ variables. So, $U({\\sqrt{3} / \\sqrt{2}})$ is t-distributed with three degrees of freedom.\n",
    "\n",
    "$$\n",
    "c = {\\sqrt{3} \\over \\sqrt{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Suppose that $X_1, . . . , X_n$ form a random sample from the normal distribution with unknown mean $μ$ and known variance $σ^2$. Let $\\Phi$ stand for the c.d.f. of the standard normal distribution, and let $\\Phi^{−1}$ be its inverse. Show that the following interval is a coefficient $γ$ confidence interval for $μ$ if $X_n$ is the observed average of the data values:**\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "    \\overline{X}_n - \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}},\n",
    "    \\overline{X}_n + \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $a$ such that,\n",
    "\n",
    "$$\n",
    "a = P(\n",
    "\\overline{X}_n - \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}}\n",
    "\\lt \\mu \\lt\n",
    "\\overline{X}_n + \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}}\n",
    ")\n",
    "$$\n",
    "\n",
    "Manipulating this expression, we get,\n",
    "\n",
    "$$\n",
    "a = P(\n",
    "- \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}}\n",
    "\\lt \\mu -\\overline{X}_n \\lt\n",
    "\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}}\n",
    ")\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = P(\n",
    "    - \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}}\n",
    "\\lt \\overline{X}_n - \\mu  \\lt\n",
    "\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = P(\n",
    "    - \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right)\n",
    "\\lt {n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)  \\lt\n",
    "\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right))\n",
    "$$\n",
    "\n",
    "Since the $X_i$ come from a normal distribution, we have that,\n",
    "\n",
    "$$\n",
    "\\overline{X}_n \\sim \\text{Normal}(\\mu, {\\sigma^2 \\over n})\n",
    "$$\n",
    "\n",
    "(Note that I am using the second argument to the normal distribution to indicate the variance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the distribution of,\n",
    "\n",
    "$$\n",
    "{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)\n",
    "$$\n",
    "\n",
    "This is a linear transformation of a normal variable. So, it is normally distributed.\n",
    "\n",
    "$$\n",
    "E[{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)] =\n",
    "{n^{1/2} \\over \\sigma}(E[\\overline{X}_n] - E[\\mu])\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)] =\n",
    "{n^{1/2} \\over \\sigma}(\\mu - \\mu)\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)] =\n",
    "0\n",
    "$$\n",
    "\n",
    "$$\n",
    "var[{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)] =\n",
    "{n \\over \\sigma^2}var[\\overline{X}_n - \\mu]\n",
    "$$\n",
    "\n",
    "Variance is translation invariant.\n",
    "\n",
    "$$\n",
    "var[{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)] =\n",
    "{n \\over \\sigma^2}var[\\overline{X}_n]\n",
    "$$\n",
    "\n",
    "$$\n",
    "var[{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)] =\n",
    "{n \\over \\sigma^2}{\\sigma^2 \\over n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "var[{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu)] =\n",
    "1\n",
    "$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\n",
    "{n^{1/2} \\over \\sigma}(\\overline{X}_n - \\mu) \\sim \\text{Normal}(0, 1)\n",
    "$$\n",
    "\n",
    "So, its CDF is given by $\\Phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,\n",
    "\n",
    "$$\n",
    "a = \\Phi(\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right)) - \\Phi(- \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right))\n",
    "$$\n",
    "\n",
    "The normal is symmetric. So,\n",
    "\n",
    "$$\n",
    "\\Phi(- \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right)) =\n",
    "1 - \\Phi(\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right))\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "a = \\Phi(\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right)) - (1 - \\Phi(\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right)))\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = 2\\Phi(\\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right)) - 1\n",
    "$$\n",
    "\n",
    "We have that $\\Phi$ and $\\Phi^{-1}$ are inverses. So,\n",
    "\n",
    "$$\n",
    "a = 2\\left({1 + \\gamma \\over 2}\\right) - 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = 1 + \\gamma - 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = \\gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown that the probabiliy that the interval,\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "    \\overline{X}_n - \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}},\n",
    "    \\overline{X}_n + \\Phi^{-1}\\left({1 + \\gamma \\over 2}\\right){\\sigma \\over n^{1/2}}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "contains $\\mu$ is equal to $\\gamma$. This suffices to show that the interval is a $\\gamma$ confidence interval for $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Suppose that a random sample of eight observations is taken from the normal distribution with unknown mean\n",
    "$μ$ and unknown variance $σ^2$, and that the observed values are 3.1, 3.5, 2.6, 3.4, 3.8, 3.0, 2.9, and 2.2. Find the shortest confidence interval for $μ$ with each of the following three confidence coefficients: (a) 0.90, (b) 0.95, and (c) 0.99.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $c_1(\\gamma) \\lt c_2(\\gamma)$ be real valued functions which minimize $c_2(\\gamma) - c_1(\\gamma)$ subject to,\n",
    "\n",
    "$$\n",
    "P(c_1(\\gamma) \\lt \\mu \\lt c_2(\\gamma) | X_1...X_n) \\ge \\gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\Phi_{n - 1}^{-1}$ denote the inverse cdf of the t distribution with $n - 1$ degrees of freedom.\n",
    "\n",
    "We can calculate the following,\n",
    "\n",
    "$$\n",
    "\\overline{X}_n = 3.0625\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma' = 0.5125217765408328\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sqrt{n} = 2.8284271247461903\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Phi_{n - 1}^{-1}\\left(0.9 + 1 \\over 2\\right) =\n",
    "\\Phi_{n - 1}^{-1}\\left(0.95\\right) =\n",
    "1.89457861\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Phi_{n - 1}^{-1}\\left(0.95 + 1 \\over 2\\right) =\n",
    "\\Phi_{n - 1}^{-1}\\left(0.975\\right) =\n",
    "2.36462425\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Phi_{n - 1}^{-1}\\left(0.99 + 1 \\over 2\\right) =\n",
    "\\Phi_{n - 1}^{-1}\\left(0.995\\right) =\n",
    "3.4994833\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,\n",
    "\n",
    "$$\n",
    "[c_1(0.9), c_2(0.9)] =\n",
    "\\left[\n",
    "    \\overline{X}_n - \\Phi_{n - 1}^{-1}\\left({1 + 0.9 \\over 2}\\right){\\sigma' \\over \\sqrt{n}},\n",
    "    \\overline{X}_n + \\Phi_{n - 1}^{-1}\\left({1 + 0.9 \\over 2}\\right){\\sigma' \\over \\sqrt{n}}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "[c_1(0.9), c_2(0.9)] =\n",
    "\\left[\n",
    "    3.0625 - 1.89457861{0.5125217765408328 \\over 2.8284271247461903},\n",
    "    3.0625 + 1.89457861{0.5125217765408328 \\over 2.8284271247461903}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "[c_1(0.9), c_2(0.9)] =\n",
    "\\left[\n",
    "    2.71919513402061,\n",
    "    3.40580486597939\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly,\n",
    "\n",
    "$$\n",
    "[c_1(0.95), c_2(0.95)] =\n",
    "[2.63402107, 3.49097893]\n",
    "$$\n",
    "\n",
    "$$\n",
    "[c_1(0.99), c_2(0.99)] =\n",
    "[2.42838029, 3.69661971]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Suppose that $X_1, . . . , X_n$ form a random sample from the exponential distribution with unknown mean $μ$. Describe a method for constructing a confidence interval for $μ$ with a specified confidence coefficient $γ$ $(0 < γ < 1)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Determine constants c1 and c2 such that Pr[c1 <\n",
    "(1/μ)n\n",
    "i=1 Xi < c2]= γ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\lambda = \\mu^{-1}$. Then,\n",
    "\n",
    "We have that,\n",
    "\n",
    "$$\n",
    "X_i \\sim \\text{Exponential}(\\lambda)\n",
    "$$\n",
    "\n",
    "Let,\n",
    "\n",
    "$$\n",
    "S = \\sum_{i = 1}^n X_i\n",
    "$$\n",
    "\n",
    "Then, by the properties of the gamma distribution,\n",
    "\n",
    "$$\n",
    "S \\sim \\text{Gamma}(n, \\lambda)\n",
    "$$\n",
    "\n",
    "So, the moment generating function of s is given by,\n",
    "\n",
    "$$\n",
    "M_S = \\left( {\\lambda \\over \\lambda - t} \\right)^n\n",
    "$$\n",
    "\n",
    "Consider the random variable $\\lambda S$. By the properties of moment generating functions, the MGF of this variable will be given by,\n",
    "\n",
    "$$\n",
    "M_{\\lambda S} = \\left( {\\lambda \\over \\lambda - t\\lambda} \\right)^n\n",
    "$$\n",
    "\n",
    "$$\n",
    "M_{\\lambda S} = \\left( {\\lambda \\over \\lambda - t\\lambda}{\\lambda^{-1} \\over \\lambda^{-1}} \\right)^n\n",
    "$$\n",
    "\n",
    "$$\n",
    "M_{\\lambda S} = \\left( {1 \\over 1 - t} \\right)^n\n",
    "$$\n",
    "\n",
    "But this is just the MGF of the gamma distribution with parameters $n$ and $1$. So,\n",
    "\n",
    "$$\n",
    "\\lambda S \\sim \\text{Gamma}(n, 1)\n",
    "$$\n",
    "\n",
    "Then, by the definition of $\\lambda$,\n",
    "\n",
    "$$\n",
    "{S \\over \\mu} \\sim \\text{Gamma}(n, 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\Phi$ denote the CDF of the gamma distribution with parameters $n$ and 1. Let $\\Phi^{-1}$ be the corresponding inverse CDF. Let $a \\lt b$ be positive real numbers.\n",
    "\n",
    "$$\n",
    "P(a \\lt \\mu^{-1} S \\lt b) = \\Phi(b) - \\Phi(a)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(aS^{-1} \\lt \\mu^{-1} \\lt bS^{-1}) = \\Phi(b) - \\Phi(a)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(a^{-1}S \\gt \\mu \\gt b^{-1}S) = \\Phi(b) - \\Phi(a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\mu^{-1}S \\lt x) = \\Phi(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(x^{-1}S \\lt \\mu) = \\Phi(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(x^{-1}S \\gt \\mu) = 1 - \\Phi(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mu \\lt y) = 1 - \\Phi(S/y)\n",
    "$$\n",
    "\n",
    "So, if $a \\lt b$,\n",
    "\n",
    "$$\n",
    "P(a \\lt \\mu \\lt b) = (1 - \\Phi(S/b)) - (1 - \\Phi(S/a))\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(a \\lt \\mu \\lt b) = \\Phi(S/a) - \\Phi(S/b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Let $X_1, . . . , X_n$ be a random sample from the Poisson distribution with mean $θ$.**\n",
    "\n",
    "**a. Express the $Var_θ(X_i)$ as a function $σ^2 = g(θ)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have that,\n",
    "\n",
    "$$\n",
    "X_i \\sim \\text{Poisson}(\\theta)\n",
    "$$\n",
    "\n",
    "It is a property of the Poisson distribution that the mean is equal to the variance. So,\n",
    "\n",
    "$$\n",
    "Var(X_i) = \\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Find the M.L.E. of $g(θ)$ and show that it is unbiased.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the $X_i$ are poisson distributed,\n",
    "\n",
    "$$\n",
    "P(X = x | \\theta) = {\\lambda^xe^{-\\theta} \\over x!} I(x \\in \\{0, 1,2...\\})\n",
    "$$\n",
    "\n",
    "Let $L(\\theta)$ be the log likelihood of $\\theta$ given $X_1...X_n$. Then,\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\ln \\left(\\prod_{i = 1}^n {\\theta^{x_i}e^{-\\theta} \\over x_i!} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\sum_{i = 1}^n \\ln \\left( {\\theta^{x_i}e^{-\\theta} \\over x_i!} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\sum_{i = 1}^n \\left( x_i \\ln(\\theta) - \\theta - \\ln(x_i!) \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "L(\\theta) =  \\left(\\sum_{i = 1}^n x_i \\ln(\\theta)\\right) - \\left(\\sum_{i = 1}^n\\theta\\right) - \\left(\\sum_{i = 1}^n \\ln(x_i!) \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "L(\\theta) =\n",
    "\\ln(\\theta)\\sum_{i = 1}^n x_i\n",
    "- n\\theta\n",
    "- \\left(\\sum_{i = 1}^n \\ln(x_i!) \\right)\n",
    "$$\n",
    "\n",
    "Let $S_n = \\sum_{i = 1}^n x_i$. Then,\n",
    "\n",
    "$$\n",
    "L(\\theta) =\n",
    "\\ln(\\theta)S_n\n",
    "- n\\theta\n",
    "- \\left(\\sum_{i = 1}^n \\ln(x_i!) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the derivative.\n",
    "\n",
    "$$\n",
    "{d \\over d\\theta} L(\\theta) = {S_n \\over \\theta} - n\n",
    "$$\n",
    "\n",
    "The MLE will be a critical point.\n",
    "\n",
    "$$\n",
    "{S_n \\over \\hat{\\theta}} - n = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "{S_n \\over \\hat{\\theta}} = n\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = {S_n \\over n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = {1 \\over n}\\sum_{i = 1}^n x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the expectation of this variable.\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] = E \\left[ {1 \\over n}\\sum_{i = 1}^n X_i \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] = {1 \\over n} E \\left[ \\sum_{i = 1}^n X_i \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] = {1 \\over n} \\sum_{i = 1}^n E \\left[ X_i \\right]\n",
    "$$\n",
    "\n",
    "We have that the mean of each $E[X_i] = \\theta$. So,\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] = {1 \\over n} \\sum_{i = 1}^n \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] = {1 \\over n} n \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] = \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] - \\theta = 0\n",
    "$$\n",
    "\n",
    "So, $\\hat{\\theta}$ is an unbiased estimator for $\\theta$. Since $Var(X_i) = \\theta$, $\\hat{\\theta}$ is an unbiased estimator for $Var(X_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Suppose that $X$ is a random variable whose distribution is completely unknown, but it is known that all the moments $E(X^k)$, for $k= 1, 2, . . . $, are finite. Suppose also that $X_1, . . . , X_n$ form a random sample from this distribution. Show that for $k= 1, 2, . . . $, the kth sample moment $(1/n) \\sum_{i=1}^n X_i^k$ is an unbiased estimator of $E(X^k)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\delta_k$ denote the kth sample moment. Take the expectation of the kth sample moment.\n",
    "\n",
    "$$\n",
    "E[\\delta_k] = E \\left[{1 \\over n}\\sum_{i = 1}^n X_i^k \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta_k] = {1 \\over n}E \\left[\\sum_{i = 1}^n X_i^k \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta_k] = {1 \\over n} \\sum_{i = 1}^n E[ X_i^k ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta_k] = {1 \\over n} \\sum_{i = 1}^n E[ X_i^k ]\n",
    "$$\n",
    "\n",
    "Since the $X_i$ are drawn from the same distribution as $X$, they have the same moments as $X$. So, $E[X_i^k] = E[X^k]$.\n",
    "\n",
    "$$\n",
    "E[\\delta_k] = {1 \\over n} \\sum_{i = 1}^n E[ X^k ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta_k] = {1 \\over n} n E[ X^k ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta_k] = E[ X^k ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta_k] - E[ X^k ] = 0\n",
    "$$\n",
    "\n",
    "So, $\\delta_k$ is an unbiased estimator for the kth moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Suppose that a random variable $X$ has the geometric distribution with unknown parameter p. (See Sec. 5.5.) Find a statistic $δ(X)$ that will be an unbiased estimator of $1/p$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $p = 0$, then ${1/p}$ is not defined. So, we will assume $p \\ne 0$.\n",
    "\n",
    "We have that,\n",
    "\n",
    "$$\n",
    "X \\sim \\text{Geometric}(p)\n",
    "$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\n",
    "P(X = x | p) = (1 - p)^xpI(x \\in \\{0, 1, 2...\\})\n",
    "$$\n",
    "\n",
    "I will find the MLE and then prove that it is unbiased.\n",
    "\n",
    "Let $L$ denote the log likelihood of $p | X$. Suppose $x \\in \\{0, 1, 2...\\}$. Then,\n",
    "\n",
    "$$\n",
    "L(p) = \\ln((1 - p)^xp)\n",
    "$$\n",
    "\n",
    "$$\n",
    "L(p) = x\\ln(1 - p) + \\ln(p)\n",
    "$$\n",
    "\n",
    "$$\n",
    "{d \\over dp}L(p) = {x \\over 1 - p} + {1 \\over p}\n",
    "$$\n",
    "\n",
    "Then, critical points of the log likelihood will be given by solutions to,\n",
    "\n",
    "$$\n",
    "{x \\over 1 - p} + {1 \\over p} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "{x \\over 1 - p} = -{1 \\over p}\n",
    "$$\n",
    "\n",
    "$$\n",
    "px = -(p - 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "px + p = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "p = {1 \\over x + 1}\n",
    "$$\n",
    "\n",
    "So, the maximum likelihood estimator of $p$ is given by,\n",
    "\n",
    "$$\n",
    "\\delta_p(x) = {1 \\over x + 1}\n",
    "$$\n",
    "\n",
    "So, by invariance, the maximum likelihood estimator of ${1 \\over p}$ is given by,\n",
    "\n",
    "$$\n",
    "\\delta(x) = x + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the expected value of this estimator.\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] = \\sum_{x = 0}^\\infty (x + 1)p(1 - p)^x\n",
    "$$\n",
    "\n",
    "Let $w = 1 - p$. Then,\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] = (1 - w)\\sum_{x = 0}^\\infty (x + 1)w^x\n",
    "$$\n",
    "\n",
    "Integrate with respect to $w$.\n",
    "\n",
    "$$\n",
    "\\int E[\\delta(x)] dw = \\int (1 - w)\\sum_{x = 0}^\\infty (x + 1)w^x dw\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let,\n",
    "\n",
    "$$\n",
    "u = \\int \\sum_{x = 0}^\\infty (x + 1)w^x dw\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "u = \\sum_{x = 0}^\\infty \\int (x + 1)w^x dw\n",
    "$$\n",
    "\n",
    "$$\n",
    "u = \\sum_{x = 0}^\\infty w^{x + 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "u = w\\sum_{x = 0}^\\infty w^{x}\n",
    "$$\n",
    "\n",
    "By assumption $p \\ne 0$, so $0 \\le w \\lt 1$. Then,\n",
    "\n",
    "$$\n",
    "u = {w \\over 1 - w}\n",
    "$$\n",
    "\n",
    "Also,\n",
    "\n",
    "$$\n",
    "du = \\sum_{x = 0}^\\infty (x + 1)w^x dw\n",
    "$$\n",
    "\n",
    "Let,\n",
    "\n",
    "$$\n",
    "v = (1 - w)\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "dv = -dw\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute,\n",
    "\n",
    "$$\n",
    "\\int (1 - w)\\sum_{x = 0}^\\infty (x + 1)w^x dw = \\int vdu\n",
    "$$\n",
    "\n",
    "Apply integration by parts.\n",
    "\n",
    "$$\n",
    "\\int (1 - w)\\sum_{x = 0}^\\infty (x + 1)w^x dw = uv - \\int udv\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\int E[\\delta(x)] dw = {w \\over 1 - w}(1 - w) - \\int {w \\over 1 - w}(-dw)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int E[\\delta(x)] dw = w + \\int {w \\over 1 - w}dw\n",
    "$$\n",
    "\n",
    "Take the derivative with respect to $w$.\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] = 1 + {w \\over 1 - w}\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] = {1 - w \\over 1 - w} + {w \\over 1 - w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] = {w  + (1 - w) \\over 1 - w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] = {1 \\over 1 - w}\n",
    "$$\n",
    "\n",
    "By the definition fo $w$.\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] = {1 \\over p}\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "E[\\delta(x)] - {1 \\over p} = 0\n",
    "$$\n",
    "\n",
    "So, $\\delta(x)$ is an unbiased estimator for $1/p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Suppose that a random variable $X$ has the Poisson distribution with unknown mean $λ$ $(λ > 0)$. Find a statistic $δ(X)$ that will be an unbiased estimator of $e^λ$.**\n",
    "\n",
    "Hint: If E[δ(X)]= e^λ, then\n",
    "$$\n",
    "\\sum_{x = 0}^\\infty {\\delta (x)e^{-\\lambda}\\lambda^x \\over x!} = e^\\lambda\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found earlier that the MLE of $\\lambda$ is,\n",
    "\n",
    "$$\n",
    "\\hat{\\lambda} = {1 \\over n}\\sum_{i = 1}^n X_i\n",
    "$$\n",
    "\n",
    "So, by invariance, the MLE for $e^\\lambda$ is,\n",
    "\n",
    "$$\n",
    "\\widehat{e^\\lambda} = \\exp \\left({1 \\over n}\\sum_{i = 1}^n X_i \\right)\n",
    "$$\n",
    "\n",
    "Take the expectation,\n",
    "\n",
    "$$\n",
    "E[\\widehat{e^\\lambda}] = E\\left[\\exp \\left({1 \\over n}\\sum_{i = 1}^n X_i \\right) \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\widehat{e^\\lambda}] = E \\left[\\exp \\left({1 \\over n}\\sum_{i = 1}^n X_i \\right) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Suppose that a random variable $X$ has the geometric distribution with unknown parameter $p$ $(0 < p < 1)$. Show that the only unbiased estimator of $p$ is the estimator $δ(X)$ such that $δ(0)= 1$ and $δ(X)= 0$ for $X > 0$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pdf of the geomtric distribution is given by,\n",
    "\n",
    "$$\n",
    "P(X = x | p) = (1 - p)^xp I(x \\in \\{0, 1, 2,...\\})\n",
    "$$\n",
    "\n",
    "Suppose $\\delta(X)$ is an unbiased estimator of $p$. Then,\n",
    "\n",
    "$$\n",
    "E[\\delta(X)] = p\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{x = 0}^\\infty \\delta(x)(1 - p)^xp = p\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{x = 0}^\\infty \\delta(x)(1 - p)^x = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta(0) + \\sum_{x = 1}^\\infty \\delta(x)(1 - p)^x = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Suppose that a certain drug is to be administered to two different types of animals $A$ and $B$. It is known that the mean response of animals of type $A$ is the same as the mean response of animals of type $B$, but the common\n",
    "value $θ$ of this mean is unknown and must be estimated. It is also known that the variance of the response of animals\n",
    "of type $A$ is four times as large as the variance of the response of animals of type $B$. Let $X_1, . . . , X_m$ denote the responses of a random sample of m animals of type $A$, and let $Y_1, . . . , Y_n$ denote the responses of an independent random sample of $n$ animals of type $B$. Finally, consider the estimator $\\hat{\\theta}= α\\overline{X}_m + (1− α)\\overline{Y}_n$.**\n",
    "\n",
    "**a. For what values of $α$, $m$, and $n$ is $\\hat{\\theta}$ an unbiased estimator of $θ$?**\n",
    "\n",
    "**b. For fixed values of $m$ and $n$, what value of $α$ yields an unbiased estimator with minimum variance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
